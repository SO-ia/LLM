{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b20b2cf82540e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:42:06.748283200Z",
     "start_time": "2025-07-19T12:41:55.046543200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2025-07-19 21:04:46.958120: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-19 21:04:47.015761: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-19 21:04:47.912990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import jieba\n",
    "import faiss\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4457ba6a6a468",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 优化/修改 rag_v0 中的中文检索器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942208e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 修改内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba40daf",
   "metadata": {},
   "source": [
    "相较于 rag_v0 修改了如下方面：\n",
    "1. 字符级分词 ---> 词语级分词\n",
    "2. 稠密检索 (v0中需使用内存存储，重启后需重建索引，不适合大规模数据)\n",
    "   1. 增加 FAISS 向量数据库方案\n",
    "   2. 增加 Milvus 向量数据库方案\n",
    "3. 独立BM25、FAISS、Bert检索类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653f7c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 检索器流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0840a-3481-4014-a07c-99b53766cc85",
   "metadata": {},
   "source": [
    "一般的 Retriever 流程如下：\n",
    "\n",
    "1. 文本预处理: 分词(英文-空格, 中文-单个字符), 清洗(去噪-HTML标签/特殊字符)\n",
    "2. 文本嵌入: 将文本转换为固定维度的向量\n",
    "3. 检索算法:\n",
    "   - 倒排索引(如 BM25)\n",
    "   - 向量检索(如 向量数据库FAISS/Milvus, BERT)\n",
    "   - 混合检索(结合向量检索和倒排索引, 初筛+精筛/综合得分)\n",
    "4. 结果重排序\n",
    "   - **相似度**：向量相似度\n",
    "   - **模型**：排序模型（如 BERT-based ranking model）对候选文档进行排序\n",
    "   - **混合排序**：多种排序方法 (如先按向量相似度排序, 再按关键词匹配度排序)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce0740",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1991642",
   "metadata": {},
   "source": [
    "##### 检索方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94900962",
   "metadata": {},
   "source": [
    "在本实验中，采用 IndexFlatIP 作为检索方法：\n",
    "1. 该方法是计算向量的 **内积** 作为度量方法\n",
    "2. 内积结果受两个因素影响:\n",
    "   1. 向量方向 (真正反映语义相似度)\n",
    "   2. 向量长度 (与语义无关的干扰因素)\n",
    "3. 实际处理中需进行归一化 --- 避免 **向量长度偏差** 问题，具体问题见下列代码块 **向量长度问题**\n",
    "4. 在 FAISS 中可直接使用 `faiss.normalize_L2(embeddings)` 进行归一化\n",
    "5. 注意存入参考文本时和查询时都须进行归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312031b1",
   "metadata": {},
   "source": [
    "##### 向量长度问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7a1ab",
   "metadata": {},
   "source": [
    "未归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2086336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_short = np.array([1, 1])  # 短文本嵌入\n",
    "vec_long = np.array([2, 2])  # 长文本嵌入\n",
    "query = np.array([1, 0])  # 参考文本嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbbf9b",
   "metadata": {},
   "source": [
    "原始内积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b79647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "短文本得分: 1\n",
      "长文本得分: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'短文本得分: {np.dot(query, vec_short)}')\n",
    "print(f'长文本得分: {np.dot(query, vec_long)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d6201",
   "metadata": {},
   "source": [
    "- 结果：\n",
    "  虽然长文本、短文本的夹角都和参考文本相同 (也就是余弦相似度应该相等)，但得到两个内积是不一样的，所以需要进行归一化\n",
    "\n",
    "- 影响：\n",
    "  1. 文本长度：长文本通常会产生更大的嵌入向量 (更多非0值)\n",
    "  2. 系统会更倾向于返回更长的文档，而不是更相关的文档 (那么在 QA 中可能导致返回包含冗余信息的段落)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdc155",
   "metadata": {},
   "source": [
    "归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7682cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)\n",
    "\n",
    "\n",
    "norm_short = normalize(vec_short)\n",
    "norm_long = normalize(vec_long)\n",
    "norm_query = normalize(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb305782",
   "metadata": {},
   "source": [
    "归一化后内积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7795a9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "短文本得分: 0.7071067811865475\n",
      "长文本得分: 0.7071067811865475\n"
     ]
    }
   ],
   "source": [
    "print(\"短文本得分:\", np.dot(norm_query, norm_short))\n",
    "print(\"长文本得分:\", np.dot(norm_query, norm_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220189a5",
   "metadata": {},
   "source": [
    "归一化后的结果就相等了，文本的相似度不会受到向量长度的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52791888",
   "metadata": {},
   "source": [
    "主流框架的处理方式\n",
    "1. FAISS: `faiss.normalize_L2(embeddings)`\n",
    "2. Milvus: 内置 `metric_type=\"IP\"` 会自动归一化\n",
    "3. Elasticsearch: `cosineSimilarity` 函数自动处理归一化\n",
    "4. SentenceTransformers: 默认返回已归一化的嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a6760",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 中文检索器类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f34cc-7e5f-457b-97bb-0e9759c8aae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 基础类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782943f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChineseRetriever:\n",
    "    \"\"\"\n",
    "    基础类: 提供文档加载和结果返回的函数，包含以下函数\n",
    "    _load_json_docs: 加载并预处理JSON文档\n",
    "    get_document: 根据索引获取完整文档\n",
    "    print_results: 格式化打印检索结果\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path: str):\n",
    "        \"\"\"\n",
    "        初始化中文检索器\n",
    "        :param json_path: JSON文件路径, 格式为[{'question':'', 'answer':''}, ...]\n",
    "        \"\"\"\n",
    "        self.docs = self._load_json_docs(json_path)\n",
    "        self.questions = [doc['question'] for doc in self.docs]\n",
    "        self.answers = [doc['answer'] for doc in self.docs]\n",
    "\n",
    "    def _load_json_docs(self, path: str) -> List[Dict]:\n",
    "        \"\"\"加载并预处理JSON文档\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            docs = json.load(f)\n",
    "\n",
    "        # 中文分词处理(按词语级分割)\n",
    "        for doc in docs:\n",
    "            doc['tokenized'] = list(jieba.cut(doc['question']))  # 按jieba的默认词典进行分词\n",
    "        return docs\n",
    "\n",
    "    def get_document(self, index: int) -> Dict:\n",
    "        \"\"\"根据索引获取完整文档\"\"\"\n",
    "        return self.docs[index]\n",
    "\n",
    "    def print_results(self, results: List[Tuple[int, float]]):\n",
    "        \"\"\"格式化打印检索结果\"\"\"\n",
    "        for rank, (idx, score) in enumerate(results, 1):\n",
    "            doc = self.get_document(idx)\n",
    "            print(f\"Rank {rank} (Score: {score:.4f}):\")\n",
    "            print(f\"Q: {doc['question']}\")\n",
    "            print(f\"A: {doc['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c62674",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc9707eae6c5fad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BM25Retriever(ChineseRetriever):\n",
    "    def __init__(self, json_path: str):\n",
    "        \"\"\"\n",
    "        初始化BM25检索器\n",
    "        :param json_path: JSON文件路径, 格式为[{'question':'', 'answer':''}, ...]\n",
    "        \"\"\"\n",
    "        super().__init__(json_path)\n",
    "\n",
    "        # 初始化稀疏检索(BM25)\n",
    "        self.bm25 = self._init_sparse_retriever()\n",
    "\n",
    "    def _init_sparse_retriever(self):\n",
    "        \"\"\"初始化BM25稀疏检索器\"\"\"\n",
    "        tokenized_corpus = [doc['tokenized'] for doc in self.docs]\n",
    "        return BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    def sparse_retrieve(self, query: str, top_k: int = 5) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        BM25稀疏检索\n",
    "        :return: 返回(top_k个(文档索引, 得分))列表, 如[(3, 8.21), (1, 6.54)...], 按得分降序排序\n",
    "        :param query: 原始查询字符串\n",
    "        :process: \n",
    "            1. 先将中文字符串转换为字符列表 (即进行文本分割), BM25基于词频统计, 中文无空格因此需主动分词, 目前仅使用字符级分词, 后续可尝试分词工具, 如 jieba\n",
    "            2. 再计算BM25得分\n",
    "            3. 最后返回前k个文档\n",
    "        \"\"\"\n",
    "        # 同样修改成使用jieba默认词典分词\n",
    "        tokenized_query = list(jieba.cut(query))\n",
    "        # BM25计算公式\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        # 前k个文档的索引\n",
    "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        '''\n",
    "        return [(i, scores[i]) for i in top_indices]\n",
    "        上述代码在当前环境 (当前环境见 requirements.txt) 中会报错如下：\n",
    "        Expression of type \"list[tuple[NDArray[intp], Any]]\" cannot be assigned to return type \"List[Tuple[int, float]]\"\n",
    "        NDArray[intp] 说明：\n",
    "            1. NDArray: NumPy数组, 表示一个多维数组, 是 numpy.ndarray 的别名\n",
    "            2. intp: 32位系统 --- 32位整数; 64位系统 --- 64位整数\n",
    "        '''\n",
    "        return [(int(i), scores[int(i)]) for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6ed6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ae7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRetriever(ChineseRetriever):\n",
    "    def __init__(self,\n",
    "                 json_path: str,\n",
    "                 model_path_or_name: str = 'bert-base-chinese'\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        初始化中文检索器\n",
    "        :param json_path: JSON文件路径, 格式为[{'question':'', 'answer':''}, ...]\n",
    "        :param model_path_or_name: 稠密检索模型名称 or 路径(默认bert-base-chinese)\n",
    "        \"\"\"\n",
    "        super().__init__(json_path)\n",
    "\n",
    "        # 初始化稠密检索(BERT)\n",
    "        self.encoder = SentenceTransformer(model_path_or_name)\n",
    "        self.doc_embeddings = self._init_dense_retriever()\n",
    "\n",
    "    def _init_dense_retriever(self) -> np.ndarray:\n",
    "        \"\"\"预计算所有文档的BERT嵌入\"\"\"\n",
    "        return self.encoder.encode(self.questions)\n",
    "\n",
    "    def dense_retrieve(self, query: str, top_k: int = 5) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        BERT稠密检索\n",
    "        :return: 返回(top_k个(文档索引, 余弦相似度))列表\n",
    "        :param query: 原始查询字符串\n",
    "        :process: \n",
    "            1. 分词器将文本转换为子词单元\n",
    "            2. 添加[CLS]/[SEP]等特殊标记\n",
    "            3. 通过12层Transformer获取[CLS]位置的768维向量\n",
    "        \"\"\"\n",
    "        # 编码\n",
    "        query_embedding = self.encoder.encode(query)\n",
    "        # 余弦相似度\n",
    "        similarities = cosine_similarity(\n",
    "            [query_embedding],\n",
    "            self.doc_embeddings\n",
    "        )[0]\n",
    "        # .argsort 顺序\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "        '''\n",
    "        return [i, similarities[i]) for i in top_indices]\n",
    "        上述代码在当前环境 (当前环境见 requirements.txt) 中会报错如下：\n",
    "        Expression of type \"list[tuple[NDArray[intp], Any]]\" cannot be assigned to return type \"List[Tuple[int, float]]\"\n",
    "        NDArray[intp] 说明：\n",
    "            1. NDArray: NumPy数组, 表示一个多维数组, 是 numpy.ndarray 的别名\n",
    "            2. intp: 32位系统 --- 32位整数; 64位系统 --- 64位整数\n",
    "        '''\n",
    "        return [(int(i), similarities[int(i)]) for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe1b2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad1e515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissRetriever(ChineseRetriever):\n",
    "    def __init__(self,\n",
    "                 json_path: str,\n",
    "                 db_dir: str = 'vector_db',\n",
    "                 model_path_or_name: str = 'bert-base-chinese'\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        初始化中文检索器\n",
    "        :param json_path: JSON文件路径, 格式为[{'question':'', 'answer':''}, ...]\n",
    "        :param model_path_or_name: 稠密检索模型名称 or 路径(默认bert-base-chinese)\n",
    "        \"\"\"\n",
    "        super().__init__(json_path=json_path)\n",
    "\n",
    "        # 初始化稠密检索(BERT)\n",
    "        self.encoder = SentenceTransformer(model_path_or_name)\n",
    "        self.doc_embeddings = self._init_dense_retriever()\n",
    "\n",
    "        # 初始化稠密检索(FAISS)\n",
    "        self.db_dir = Path(db_dir)\n",
    "        self.db_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # 初始化检索系统\n",
    "        self._init_faiss()\n",
    "\n",
    "    def _init_dense_retriever(self) -> np.ndarray:\n",
    "        \"\"\"预计算所有文档的BERT嵌入\"\"\"\n",
    "        return self.encoder.encode(self.questions)\n",
    "\n",
    "    def _init_faiss(self):\n",
    "        \"\"\"初始化FAISS向量数据库\"\"\"\n",
    "        db_path = self.db_dir / 'faiss.index'\n",
    "        if db_path.exists():\n",
    "            self.faiss_index = faiss.read_index(str(db_path))\n",
    "        else:\n",
    "            # 将numpy数组转换为FAISS需要的格式\n",
    "            vec = self.doc_embeddings.astype('float32')\n",
    "            '''\n",
    "            构建索引:\n",
    "            1. 由于文本相似度的衡量一般使用余弦相似度，那么可以通过 单位向量内积=余弦相似度\n",
    "            2. 单位向量，即L2范数=1的向量\n",
    "            3. 选用IndexFlatIP: IP是指内积（Inner Product）, 对向量进行L2正则化之后再内积就相当于计算余弦相似度\n",
    "            '''\n",
    "            # 这里需传入一个向量的维度，从而创建一个空的索引\n",
    "            self.faiss_index = faiss.IndexFlatIP(vec.shape[1])\n",
    "\n",
    "            # 归一化\n",
    "            faiss.normalize_L2(vec)\n",
    "\n",
    "            '''\n",
    "            如果想自定义 id，需要注意: IndexFlatIP 创建映射时不支持 add_with_ids\n",
    "            因此在创建 Index 时需要传入一个 IndexIDMap\n",
    "            然后将 向量嵌入vec 和 xids 一起加入到 FAISS 中\n",
    "            '''\n",
    "            # xids = np.array([i for i in range(1, vec.shape[0] + 1)])\n",
    "            # IDMap_index = faiss.IndexIDMap(self.faiss_index)\n",
    "            # IDMap_index.add_with_ids(vec, xids)\n",
    "\n",
    "            # 将向量数据加入索引\n",
    "            # 当前版本需要传入 vec.shape[0] 获取向量数量\n",
    "            # 否则会报错 Argument missing for parameter \"x\"\n",
    "            # e.g. self.faiss_index.add(vec.shape[0], vec)\n",
    "            ##############################################\n",
    "            # faiss-cpu 1.10.0 版本无需添加 vec.shape[0]\n",
    "            self.faiss_index.add(vec)\n",
    "\n",
    "            # 最后保存索引\n",
    "            faiss.write_index(self.faiss_index, str(db_path))\n",
    "\n",
    "    def faiss_retrieve(self,\n",
    "                       query: str,\n",
    "                       top_k: int = 5,\n",
    "                       ) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        FAISS 向量数据库检索\n",
    "\n",
    "        Args:\n",
    "            query (str): 原始查询字符串\n",
    "            top_k (int, optional): 选取前 K 个文档. Defaults to 5.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[int, float]]: 包含(top_k个(文档索引, 相似度得分))的列表，\n",
    "                                    得分范围[-1,1]，1表示完全相似\n",
    "                                    示例: [(0, 0.92), (2, 0.85), ...]\n",
    "        \"\"\"\n",
    "        # 编码\n",
    "        query_embedding = self.encoder.encode(query).astype('float32')\n",
    "\n",
    "        # 确保向量是2D数组 (1, embedding_dim)\n",
    "        if len(query_embedding.shape) == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "\n",
    "        # 归一化 (使得内积等价于余弦相似度)\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "\n",
    "        # FAISS 检索 (返回形状 (1, top_k))\n",
    "        scores, indices = self.faiss_index.search(\n",
    "            query_embedding,\n",
    "            top_k\n",
    "        )\n",
    "\n",
    "        # (编号, 得分)\n",
    "        # if idx != -1: 过滤无效匹配项\n",
    "        results = [(int(idx), float(score)) for idx, score in zip(indices[0], scores[0]) if idx != -1]\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de57bab85b33d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6463a67cb56a2cdb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HybridRetriever(ChineseRetriever):\n",
    "    \"\"\"混合检索器类，组合稀疏检索和稠密检索\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 json_path: str,\n",
    "                 weight: float = 0.6,\n",
    "                 model_path_or_name: str = 'bert-base-chinese'\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        初始化混合检索器\n",
    "        :param json_path: JSON文件路径, 格式为[{'question':'', 'answer':''}, ...]\n",
    "        :param weight: 稠密检索的权重（0-1之间）\n",
    "        #\n",
    "        :param bert_retriever: 稠密检索器 BertRetriever 实例\n",
    "        :param faiss_retriever: 稠密检索器 FaissRetriever 实例\n",
    "        :param bm25_retriever: 稀疏检索器 BM25Retriever 实例\n",
    "        \"\"\"\n",
    "        super().__init__(json_path)\n",
    "        self.weight = weight\n",
    "        self.model_path_or_name = model_path_or_name\n",
    "\n",
    "        self.bert_retriever = BertRetriever(json_path=json_path, model_path_or_name=self.model_path_or_name)\n",
    "        self.faiss_retriever = FaissRetriever(json_path=json_path, model_path_or_name=self.model_path_or_name)\n",
    "        self.bm25_retriever = BM25Retriever(json_path=json_path)\n",
    "\n",
    "    def bm25_bert_retrieve(self, query: str, top_k: int = 5, dense_weight: float = None) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        混合检索(默认稠密权重0.6, 稀疏权重0.4)\n",
    "        :param dense_weight: 稠密检索得分权重\n",
    "        :return: 返回(top_k个(文档索引, 综合得分))列表\n",
    "        \"\"\"\n",
    "        # 在未传值时使用self.weight\n",
    "        if dense_weight is None:\n",
    "            dense_weight = self.weight\n",
    "\n",
    "        # 各自检索2倍于最终需要的文档量, 扩大候选池\n",
    "        bm25_results = dict(self.bm25_retriever.sparse_retrieve(query, top_k * 2))\n",
    "        bert_results = dict(self.bert_retriever.dense_retrieve(query, top_k * 2))\n",
    "\n",
    "        # 归一化得分\n",
    "        # BM25得分范围[0, +∞]\n",
    "        max_sparse = max(bm25_results.values()) if bm25_results else 1\n",
    "        # bert 余弦相似度[-1, 1]\n",
    "        max_dense = max(bert_results.values()) if bert_results else 1\n",
    "\n",
    "        # 融合得分\n",
    "        fused_scores = {}\n",
    "        all_indices = set(bm25_results.keys()) | set(bert_results.keys())\n",
    "        for idx in all_indices:\n",
    "            norm_sparse = bm25_results.get(idx, 0) / max_sparse\n",
    "            norm_dense = bert_results.get(idx, 0) / max_dense\n",
    "            fused_scores[idx] = dense_weight * norm_dense + (1 - dense_weight) * norm_sparse\n",
    "\n",
    "        # 返回top_k结果\n",
    "        top_indices = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return top_indices\n",
    "\n",
    "    def bm25_faiss_retrieve(self, query: str, top_k: int = 5, dense_weight: float = None) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        混合检索(默认稠密权重0.6, 稀疏权重0.4)\n",
    "        :param dense_weight: 稠密检索得分权重\n",
    "        :return: 返回(top_k个(文档索引, 综合得分))列表\n",
    "        \"\"\"\n",
    "        # 在未传值时使用self.weight\n",
    "        if dense_weight is None:\n",
    "            dense_weight = self.weight\n",
    "\n",
    "        # 各自检索2倍于最终需要的文档量, 扩大候选池\n",
    "        bm25_results = dict(self.bm25_retriever.sparse_retrieve(query, top_k * 2))\n",
    "        faiss_results = dict(self.faiss_retriever.faiss_retrieve(query, top_k * 2))\n",
    "\n",
    "        # 归一化得分\n",
    "        # BM25得分范围[0, +∞]\n",
    "        max_sparse = max(bm25_results.values()) if bm25_results else 1\n",
    "        # faiss 内积[-1, 1]\n",
    "        max_dense = max(faiss_results.values()) if faiss_retriever else 1\n",
    "\n",
    "        # 融合得分\n",
    "        fused_scores = {}\n",
    "        all_indices = set(bm25_results.keys()) | set(faiss_results.keys())\n",
    "        for idx in all_indices:\n",
    "            norm_sparse = bm25_results.get(idx, 0) / max_sparse\n",
    "            norm_dense = faiss_results.get(idx, 0) / max_dense\n",
    "            fused_scores[idx] = dense_weight * norm_dense + (1 - dense_weight) * norm_sparse\n",
    "\n",
    "        # 返回top_k结果\n",
    "        top_indices = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return top_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55fa47d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### python 路径操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0bbfa",
   "metadata": {},
   "source": [
    "传统路径操作如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'index.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a4a33",
   "metadata": {},
   "source": [
    "现代Path方式\n",
    "1. 与传统方式等效\n",
    "2. Path('data') 创建Path对象\n",
    "3. / 运算符重载为路径拼接\n",
    "4. 自动处理不同OS的路径分隔符 (Linux:/ Windows:\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = Path('data') / 'index.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8875c3e",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a396e228-29cd-4649-93f3-6e8f25d94b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试查询\n",
    "query = \"注册公司有哪些注意事项\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207b493678235c7",
   "metadata": {},
   "source": [
    "##### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17df80879e9c07e0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.588 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 初始化检索器\n",
    "bm25Retriever = BM25Retriever(json_path=\"QA_公司法.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fef9f42-41d2-494c-bc79-f747938d3abf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-19 21:05:28\n",
      "========================================\n",
      "稀疏检索结果(BM25):\n",
      "Rank 1 (Score: 22.4545):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 3、费用\n",
      "\n",
      "Rank 2 (Score: 22.4545):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 企业按组建形式可以分为有限公司、个人独资企业、合伙企业。目前，90%以上的企业类型为有限公司(以注册资本承担对外赔偿限额)，而个人独资企业或合伙企业因投资者承担无限责任而选择这2种企业类型的较少。\n",
      "\n",
      "Rank 3 (Score: 22.4545):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 首先，办理公司注册登记，需特别注意的是在公司经营范围中需加上“从事货物及技术的进出口业务”这一条。有了这条经营范围就才能申请进出口备案。从事进出口业务的也写清楚具体的业务范围。其次，在公司注册完毕及银行开户之后，申请进出口备案。进出口备案包括海关、电子口岸、外汇、检验检疫等备案手续。\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"=\" * 40 + \"\\n稀疏检索结果(BM25):\")\n",
    "bm25_results = bm25Retriever.sparse_retrieve(query=query, top_k=3)\n",
    "bm25Retriever.print_results(bm25_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128356f",
   "metadata": {},
   "source": [
    "##### 稠密检索(BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a44312d107e5269c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/autodl-tmp/data/models/bert-base-chinese. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# 初始化检索器\n",
    "bertRetriever = BertRetriever(json_path=\"QA_公司法.json\", model_path_or_name='/root/autodl-tmp/data/models/bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8efd78-1fb9-42ce-9349-6d33814cfdd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-19 21:05:58\n",
      "========================================\n",
      "稠密检索结果(BERT):\n",
      "Rank 1 (Score: 0.9319):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 5、进出口权\n",
      "\n",
      "Rank 2 (Score: 0.9319):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 按照《公司法》的规定，有限公司最低注册资本为3万元人民币，其中，一人有限公司最低注册资本为10万元人民币。注册资本可以分期出资，首批不低于20%，其余注册资本可在2年内到位。但是，不同对于最低注册资本的要求是不一样的。例如，国际货运代理公司要求最低注册资本为500元人民币。需注意的是，任何公司在设立登记时，除了要符合公司法对注册资本的要求，也要符合行业法规对最低注册资本的规定。在还需符合外资企业法律法规对于注册资本的要求\n",
      "\n",
      "Rank 3 (Score: 0.9319):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 首先，办理公司注册登记，需特别注意的是在公司经营范围中需加上“从事货物及技术的进出口业务”这一条。有了这条经营范围就才能申请进出口备案。从事进出口业务的也写清楚具体的业务范围。其次，在公司注册完毕及银行开户之后，申请进出口备案。进出口备案包括海关、电子口岸、外汇、检验检疫等备案手续。\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"=\" * 40 + \"\\n稠密检索结果(BERT):\")\n",
    "bert_results = bertRetriever.dense_retrieve(query=query, top_k=3)\n",
    "bertRetriever.print_results(bert_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34039d",
   "metadata": {},
   "source": [
    "##### 稠密检索(FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93b781368fbc3b92",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/autodl-tmp/data/models/bert-base-chinese. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "faiss_retriever = FaissRetriever(json_path='QA_公司法.json', model_path_or_name='/root/autodl-tmp/data/models/bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76205c3ca847850d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "稠密检索结果(FAISS):\n",
      "Rank 1 (Score: 0.9319):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 首先，办理公司注册登记，需特别注意的是在公司经营范围中需加上“从事货物及技术的进出口业务”这一条。有了这条经营范围就才能申请进出口备案。从事进出口业务的也写清楚具体的业务范围。其次，在公司注册完毕及银行开户之后，申请进出口备案。进出口备案包括海关、电子口岸、外汇、检验检疫等备案手续。\n",
      "\n",
      "Rank 2 (Score: 0.9319):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 企业按组建形式可以分为有限公司、个人独资企业、合伙企业。目前，90%以上的企业类型为有限公司(以注册资本承担对外赔偿限额)，而个人独资企业或合伙企业因投资者承担无限责任而选择这2种企业类型的较少。\n",
      "\n",
      "Rank 3 (Score: 0.9319):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 5、进出口权\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 40 + \"\\n稠密检索结果(FAISS):\")\n",
    "faiss_results = faiss_retriever.faiss_retrieve(query=query, top_k=3)\n",
    "faiss_retriever.print_results(faiss_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd147b8f8aa0f2c",
   "metadata": {},
   "source": [
    "##### 混合检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827f7b8bf275f7e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/autodl-tmp/data/models/bert-base-chinese. Creating a new one with mean pooling.\n",
      "No sentence-transformers model found with name /root/autodl-tmp/data/models/bert-base-chinese. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "hybrid_retriever = HybridRetriever(json_path='QA_公司法.json', model_path_or_name='/root/autodl-tmp/data/models/bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfd07f90066b1a61",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "混合检索结果(bm25 + bert):\n",
      "Rank 1 (Score: 1.0000):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 对于贸易公司或进出口公司来说，基本上都要申请一般纳税人资格(开具增值税专用发票)。各个区或同一个区的不同税务所对于企业申请一般纳税人资格的要求或规定是有些差异的\n",
      "\n",
      "Rank 2 (Score: 1.0000):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 首先，办理公司注册登记，需特别注意的是在公司经营范围中需加上“从事货物及技术的进出口业务”这一条。有了这条经营范围就才能申请进出口备案。从事进出口业务的也写清楚具体的业务范围。其次，在公司注册完毕及银行开户之后，申请进出口备案。进出口备案包括海关、电子口岸、外汇、检验检疫等备案手续。\n",
      "\n",
      "Rank 3 (Score: 1.0000):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 2、要求\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 40 + \"\\n混合检索结果(bm25 + bert):\")\n",
    "bm25_bert_results = hybrid_retriever.bm25_bert_retrieve(query=query, top_k=3)\n",
    "hybrid_retriever.print_results(bm25_bert_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2570992adbf2dddb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "混合检索结果(bm25 + faiss):\n",
      "Rank 1 (Score: 1.0000):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 首先，办理公司注册登记，需特别注意的是在公司经营范围中需加上“从事货物及技术的进出口业务”这一条。有了这条经营范围就才能申请进出口备案。从事进出口业务的也写清楚具体的业务范围。其次，在公司注册完毕及银行开户之后，申请进出口备案。进出口备案包括海关、电子口岸、外汇、检验检疫等备案手续。\n",
      "\n",
      "Rank 2 (Score: 1.0000):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 企业按组建形式可以分为有限公司、个人独资企业、合伙企业。目前，90%以上的企业类型为有限公司(以注册资本承担对外赔偿限额)，而个人独资企业或合伙企业因投资者承担无限责任而选择这2种企业类型的较少。\n",
      "\n",
      "Rank 3 (Score: 1.0000):\n",
      "Q: 您好！请问注册公司需要多长时间。有哪些注意事项\n",
      "A: 3、费用\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 40 + \"\\n混合检索结果(bm25 + faiss):\")\n",
    "bm25_faiss_results = hybrid_retriever.bm25_faiss_retrieve(query=query, top_k=3)\n",
    "hybrid_retriever.print_results(bm25_faiss_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
